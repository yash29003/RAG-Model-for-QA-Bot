// Install Required Libraries
pip install scikit-learn spacy nltk
python -m spacy download en_core_web_sm  # Download NER model for English

//Preprocessing and Chunking
import nltk
from nltk.tokenize import sent_tokenize

nltk.download('punkt')

def chunk_text(text, max_chunk_size=200):
    """Split text into chunks of a specified size."""
    sentences = sent_tokenize(text)
    chunks = []
    current_chunk = ""
    
    for sentence in sentences:
        if len(current_chunk) + len(sentence) <= max_chunk_size:
            current_chunk += sentence + " "
        else:
            chunks.append(current_chunk.strip())
            current_chunk = sentence + " "
    
    if current_chunk:
        chunks.append(current_chunk.strip())
    
    return chunks

//Named Entity Recognition (NER)
import spacy

# Load the pre-trained NER model
nlp = spacy.load("en_core_web_sm")

def extract_entities(text):
    """Extract entities from a chunk of text using NER."""
    doc = nlp(text)
    entities = [(ent.text, ent.label_) for ent in doc.ents]
    return entities

//TF-IDF Scoring
from sklearn.feature_extraction.text import TfidfVectorizer

def compute_tfidf_scores(chunks, query):
    """Calculate TF-IDF scores for each chunk based on the query."""
    vectorizer = TfidfVectorizer(stop_words="english")
    # Fit the TF-IDF model on the chunks and transform the query
    tfidf_matrix = vectorizer.fit_transform(chunks)
    query_vector = vectorizer.transform([query])
    
    # Compute cosine similarity between query and each chunk
    cosine_similarities = (tfidf_matrix * query_vector.T).toarray().flatten()
    return cosine_similarities

//Combining NER and TF-IDF
def rank_chunks_using_ner_and_tfidf(chunks, query):
    """Rank chunks based on both NER and TF-IDF scores."""
    # Get TF-IDF scores
    tfidf_scores = compute_tfidf_scores(chunks, query)
    
    chunk_scores = []
    
    for i, chunk in enumerate(chunks):
        # Extract entities using NER
        entities = extract_entities(chunk)
        
        # Assign a higher score to chunks with important entities
        ner_boost = len(entities) * 0.1  # Boost score for more entities
        
        # Final score: TF-IDF score + NER boost
        final_score = tfidf_scores[i] + ner_boost
        chunk_scores.append((chunk, final_score))
    
    # Sort chunks by their final score
    ranked_chunks = sorted(chunk_scores, key=lambda x: x[1], reverse=True)
    
    return ranked_chunks

